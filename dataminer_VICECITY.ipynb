{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cd28d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "35e10672",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"profiles\\\\vicecity_profile_1.html\", 'r') as temp:\n",
    "    profile_html = temp.read()\n",
    "\n",
    "soup = BeautifulSoup(profile_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a9d20be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_profiles_info(profiles):\n",
    "    \n",
    "    #####################\n",
    "    ###### PGP-key ######\n",
    "    #####################\n",
    "    def get_pgp_key(soup):\n",
    "        begin_tag = \"-----BEGIN PGP PUBLIC KEY BLOCK-----\"\n",
    "        end_tag   = \"-----END PGP PUBLIC KEY BLOCK-----\"\n",
    "\n",
    "        pgpbox  = soup.find(\"div\", {\"class\": \"pgp_box\"}).text\n",
    "        PGP_KEY = pgpbox.strip(begin_tag).strip(end_tag).strip()\n",
    "\n",
    "        return PGP_KEY\n",
    "\n",
    "    #####################\n",
    "    ###### Vendor #######\n",
    "    #####################\n",
    "    def get_vendor_info(soup):\n",
    "        profile_div = soup.find(\"div\", {\"class\": \"profile_image center\"})\n",
    "\n",
    "        VENDOR_NAME = profile_div.find(\"span\").text\n",
    "\n",
    "        col_4_spans = soup.find(\"div\", {\"class\": \"col-4\"}).findAll(\"span\")\n",
    "        LAST_SEEN, JOIN_DATE = [div.text for div in col_4_spans]\n",
    "        bio_div = soup.find(\"div\", {\"class\": \"bubble\"})\n",
    "        BIO = bio_div.find(\"p\").text\n",
    "\n",
    "        SALES = int(soup.select(\"label:contains(Sales)\")[0].next_sibling.next_sibling.text)\n",
    "        FEEDBACK_SCORE = int(soup.select(\"label:contains(Feedback)\")[1].next_sibling.next_sibling.text)\n",
    "\n",
    "        PGP_KEY = get_pgp_key(soup)\n",
    "\n",
    "        VENDOR_INFO =  {\"Vendor\": {\"Name\": VENDOR_NAME,\n",
    "                       \"Last seen\": LAST_SEEN,\n",
    "                       \"Join date\": JOIN_DATE,\n",
    "                       \"Sales\": SALES,\n",
    "                       \"Feedback Score\": FEEDBACK_SCORE,\n",
    "                       \"Bio\": BIO, \n",
    "                       \"PGP-key\": PGP_KEY}}\n",
    "\n",
    "        return pd.DataFrame(VENDOR_INFO).T\n",
    "\n",
    "    #####################\n",
    "    ###### Products #####\n",
    "    #####################\n",
    "    def get_products(soup):\n",
    "        # Product names\n",
    "        products = soup.find_all(\"div\", {\"class\": \"wLfRight\"})\n",
    "        product_names = [product.get_text() for product in soup.find_all(\"div\", {\"class\": \"wLfName\"})]\n",
    "\n",
    "        # Product Prices\n",
    "        product_prices_raw = [product.get_text().split(\"USD\")[0] for product in soup.find_all(\"div\", {\"class\": \"wLfPrice\"})]\n",
    "        product_prices = [int(float(price.split(\".\")[0].replace(\",\", \"\"))) for price in product_prices_raw] # missed a couple cents\n",
    "\n",
    "        # Product vendor\n",
    "        vendor_names = [product.get_text().replace(\"\\\\xa0\", \" \").split()[0] for product in soup.find_all(\"div\", {\"class\": \"wLfVendor\"})]\n",
    "        product_keys = [\"product \" + str(i + 1) for i in range(len(products))]\n",
    "\n",
    "        # Combine product info into dict\n",
    "        IDENTIFIER = list(get_vendor_info(soup)[\"Name\"])[0]\n",
    "        identifier_list = [IDENTIFIER for i in range(len(products))]\n",
    "        ALL_PRODUCTS = {product_keys[i] :\n",
    "                            {\"Product\" : product_names[i],\n",
    "                             \"Price\" : product_prices[i],\n",
    "                             \"Vendor\": vendor_names[i],\n",
    "                             \"IDENTIFIER\" : identifier_list[i]} for i in range(len(products))}\n",
    "\n",
    "        return pd.DataFrame(ALL_PRODUCTS).T\n",
    "\n",
    "\n",
    "    #####################\n",
    "    #Profile Discussions#\n",
    "    #####################\n",
    "    def get_discussion_info(soup):\n",
    "        discussion_bodies = soup.find_all(\"div\", {\"class\": \"discussion_body\"})\n",
    "        discussion_texts  = [discussion.find(\"p\").text for discussion in discussion_bodies]\n",
    "\n",
    "        discussion_headerblocks = soup.find_all(\"div\", {\"class\": \"discussionHeaderBlock\"})\n",
    "\n",
    "        discussion_poster = [header.find(\"a\").text.split(\"<span \")[0] for header in discussion_headerblocks if type(header.find(\"a\")) != type(None)]\n",
    "        discussion_poster = [poster.replace(\"\\\\xa0\", \" \").split()[0] for poster in discussion_poster]\n",
    "\n",
    "        discussion_post_date = [header.findAll(\"span\")[1].text.strip() for header in discussion_headerblocks if type(header.find(\"span\")) != type(None)]\n",
    "\n",
    "\n",
    "        # Combine discussion info into dict\n",
    "        discussion_keys = [\"Discussion \" + str(i + 1) for i in range(len(products))]\n",
    "        IDENTIFIER = list(get_vendor_info(soup)[\"Name\"])[0]\n",
    "        identifier_list = [IDENTIFIER for i in range(len(products))]\n",
    "\n",
    "        ALL_DISCUSSIONS = {discussion_keys[i] :\n",
    "                            {\"Poster\" : discussion_poster[i],\n",
    "                             \"Text\" : discussion_texts[i],\n",
    "                             \"Date\": discussion_post_date[i],\n",
    "                             \"IDENTIFIER\" : identifier_list[i]} for i in range(len(discussion_bodies))}\n",
    "\n",
    "        return pd.DataFrame(ALL_DISCUSSIONS).T\n",
    "\n",
    "    #####################\n",
    "    ### Buyer Feedback ##\n",
    "    #####################\n",
    "    def get_feedback(soup):\n",
    "        feedbacks = soup.find_all(\"div\", {\"class\": \"feedback\"})\n",
    "        feedback_subs = soup.find_all(\"div\", {\"class\": \"feedback_subheader\"})\n",
    "\n",
    "        PRODUCTS = [feedback.findAll(\"a\")[0].text.strip() for feedback in feedbacks]\n",
    "        POSTED_BY = [feedback.findAll(\"a\")[2].text.replace(\"\\\\xa0\", \" \").split()[0] for feedback in feedbacks]\n",
    "        POSTED_ON = [feedback.findAll(\"span\")[0].text.split(\"Ã¢\")[0] for feedback in feedbacks]\n",
    "\n",
    "        feedbacks_p = [feedback.findAll(\"p\") for feedback in feedbacks]\n",
    "        FEEDBACK_TEXTS = [(feedback_p[0].text if len(feedback_p) > 0 else \"\" ) for feedback_p in feedbacks_p]\n",
    "        APPROX_AMOUNT  = [int(feedback_sub.find(\"div\", {\"style\":\"float:right\"}).text.strip().split()[0][1:]) for feedback_sub in feedback_subs]\n",
    "\n",
    "        feedback_keys = [\"Feedback \" + str(i + 1) for i in range(len(feedbacks))]\n",
    "        IDENTIFIER = list(get_vendor_info(soup)[\"Name\"])[0]\n",
    "        identifier_list = [IDENTIFIER for i in range(len(products))]\n",
    "\n",
    "        ALL_FEEDBACK = {feedback_keys[i]: \n",
    "                        {\n",
    "                            \"Posted by\": POSTED_BY[i],\n",
    "                            \"Posted on\": POSTED_ON[i],\n",
    "                            \"Product\": PRODUCTS[i],\n",
    "                            \"Feedback text\": FEEDBACK_TEXTS[i],\n",
    "                            \"Approximate amount (USD)\": APPROX_AMOUNT[i],\n",
    "                            \"IDENTIFIER\": identifier_list[i]\n",
    "                        } for i in range(len(feedbacks))}\n",
    "        return pd.DataFrame(ALL_FEEDBACK).T\n",
    "    \n",
    "    \n",
    "    df_vendors  = pd.DataFrame()\n",
    "    df_products = pd.DataFrame()\n",
    "    df_discussions = pd.DataFrame()\n",
    "    df_feedback = pd.DataFrame()\n",
    "    \n",
    "    for profile in profiles:\n",
    "        with open(\"profiles\\\\\" + profile, 'r') as temp:\n",
    "            profile_html = temp.read()\n",
    "\n",
    "        soup = BeautifulSoup(profile_html, \"html.parser\")\n",
    "        \n",
    "        df_vendors = pd.concat([df_vendors, get_vendor_info(soup)])\n",
    "        df_products = pd.concat([df_products, get_products(soup)])\n",
    "        df_discussions = pd.concat([df_discussions, get_discussion_info(soup)])\n",
    "        df_feedback = pd.concat([df_feedback, get_feedback(soup)])\n",
    "        \n",
    "    \n",
    "    df_vendors.to_csv(\"VICECITY_vendor_info.csv\")\n",
    "    df_products.to_csv(\"VICECITY_products_info.csv\")\n",
    "    df_discussions.to_csv(\"VICECITY_discussions_info.csv\")\n",
    "    df_feedback.to_csv(\"VICECITY_feedback_info.csv\")\n",
    "\n",
    "    return df_vendors, df_products, df_discussions, df_feedback\n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "d1ebbc2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profiles = [\"vicecity_profile_1.html\",\"vicecity_profile_2.html\"]\n",
    "\n",
    "vendors, products, discussions, feedback = get_profiles_info(profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "1f11e305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poster</th>\n",
       "      <th>Text</th>\n",
       "      <th>Date</th>\n",
       "      <th>IDENTIFIER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Discussion 1</th>\n",
       "      <td>t****7</td>\n",
       "      <td>Hi I wanted to buy your 7days tutorial listing</td>\n",
       "      <td>November 2021</td>\n",
       "      <td>Fraudbuddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discussion 2</th>\n",
       "      <td>fraudbuddy</td>\n",
       "      <td>PROOF PROOF PROOF</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>Fraudbuddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discussion 3</th>\n",
       "      <td>a****2</td>\n",
       "      <td>He buys from himself to gives himself  feedbac...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>Fraudbuddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discussion 4</th>\n",
       "      <td>bajie1</td>\n",
       "      <td>careful with your words so as not to be the on...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>Fraudbuddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discussion 5</th>\n",
       "      <td>a****2</td>\n",
       "      <td>Do not buy he is a professional scammers\\nHes ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>Fraudbuddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discussion 6</th>\n",
       "      <td>fraudbuddy</td>\n",
       "      <td>please before you come here and be sending fud...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>Fraudbuddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discussion 7</th>\n",
       "      <td>d****9</td>\n",
       "      <td>Hey he has a good REPUTATION WITH ME SENT HIM ...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>Fraudbuddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discussion 8</th>\n",
       "      <td>S****o</td>\n",
       "      <td>aint nothing more important then the mula</td>\n",
       "      <td>January 2021</td>\n",
       "      <td>Fraudbuddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discussion 9</th>\n",
       "      <td>S****3</td>\n",
       "      <td>Hey looking for a stable partner.</td>\n",
       "      <td>December 2020</td>\n",
       "      <td>Fraudbuddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discussion 10</th>\n",
       "      <td>fraudbuddy</td>\n",
       "      <td>lol your so funny</td>\n",
       "      <td>August 2020</td>\n",
       "      <td>Fraudbuddy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Discussion 11</th>\n",
       "      <td>n****n</td>\n",
       "      <td>Hey Fraud Buddy Is A Fake Ass Western Union  F...</td>\n",
       "      <td>August 2020</td>\n",
       "      <td>Fraudbuddy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Poster                                               Text  \\\n",
       "Discussion 1       t****7    Hi I wanted to buy your 7days tutorial listing    \n",
       "Discussion 2   fraudbuddy                                  PROOF PROOF PROOF   \n",
       "Discussion 3       a****2  He buys from himself to gives himself  feedbac...   \n",
       "Discussion 4       bajie1  careful with your words so as not to be the on...   \n",
       "Discussion 5       a****2  Do not buy he is a professional scammers\\nHes ...   \n",
       "Discussion 6   fraudbuddy  please before you come here and be sending fud...   \n",
       "Discussion 7       d****9  Hey he has a good REPUTATION WITH ME SENT HIM ...   \n",
       "Discussion 8       S****o          aint nothing more important then the mula   \n",
       "Discussion 9       S****3                  Hey looking for a stable partner.   \n",
       "Discussion 10  fraudbuddy                                  lol your so funny   \n",
       "Discussion 11      n****n  Hey Fraud Buddy Is A Fake Ass Western Union  F...   \n",
       "\n",
       "                        Date  IDENTIFIER  \n",
       "Discussion 1   November 2021  Fraudbuddy  \n",
       "Discussion 2        May 2021  Fraudbuddy  \n",
       "Discussion 3        May 2021  Fraudbuddy  \n",
       "Discussion 4        May 2021  Fraudbuddy  \n",
       "Discussion 5        May 2021  Fraudbuddy  \n",
       "Discussion 6   February 2021  Fraudbuddy  \n",
       "Discussion 7   February 2021  Fraudbuddy  \n",
       "Discussion 8    January 2021  Fraudbuddy  \n",
       "Discussion 9   December 2020  Fraudbuddy  \n",
       "Discussion 10    August 2020  Fraudbuddy  \n",
       "Discussion 11    August 2020  Fraudbuddy  "
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discussions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "217c5bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fraudbuddy'"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1376aba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
